{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "_cell_guid": "b1076dfc-b9ad-4769-8c92-a6c4dae69d19",
    "_uuid": "8f2839f25d086af736a60e9eeb907d3b93b6e0e5",
    "execution": {
     "execution_failed": "2025-11-02T07:59:42.362Z",
     "iopub.execute_input": "2025-11-02T05:29:07.294245Z",
     "iopub.status.busy": "2025-11-02T05:29:07.294039Z",
     "iopub.status.idle": "2025-11-02T07:19:41.852034Z"
    },
    "trusted": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Using dataset root: /kaggle/input/betel-leaf\n",
      "Total images found: 893\n",
      "                                                path    class  \\\n",
      "0  /kaggle/input/betel-leaf/Controlled Environmen...  Healthy   \n",
      "1  /kaggle/input/betel-leaf/Controlled Environmen...  Healthy   \n",
      "2  /kaggle/input/betel-leaf/Controlled Environmen...  Healthy   \n",
      "3  /kaggle/input/betel-leaf/Controlled Environmen...  Healthy   \n",
      "4  /kaggle/input/betel-leaf/Controlled Environmen...  Healthy   \n",
      "\n",
      "                    split  \n",
      "0  Controlled Environment  \n",
      "1  Controlled Environment  \n",
      "2  Controlled Environment  \n",
      "3  Controlled Environment  \n",
      "4  Controlled Environment  \n",
      "\n",
      "Class balance:\n",
      "                     split     class  count\n",
      "0  Controlled Environment  Diseased    220\n",
      "1  Controlled Environment     Dried    340\n",
      "2  Controlled Environment   Healthy    333\n",
      "\n",
      "Global class counts:\n",
      "       class  count\n",
      "0     Dried    340\n",
      "1   Healthy    333\n",
      "2  Diseased    220\n",
      "\n",
      "Computing per-image statistics ...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 893/893 [1:49:48<00:00,  7.38s/it]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Saved per-image stats to: /kaggle/working/eda_outputs/per_image_stats.csv\n",
      "\n",
      "Per-class summary:\n",
      "            width_mean  width_min  width_max  height_mean  height_min  \\\n",
      "class                                                                  \n",
      "Diseased  6112.000000       6112       6112  6112.000000        6112   \n",
      "Dried     6110.455882       5801       6112  6110.455882        5801   \n",
      "Healthy   6112.000000       6112       6112  6112.000000        6112   \n",
      "\n",
      "          height_max  aspect_ratio_mean  aspect_ratio_min  aspect_ratio_max  \\\n",
      "class                                                                         \n",
      "Diseased        6112                1.0               1.0               1.0   \n",
      "Dried           6112                1.0               1.0               1.0   \n",
      "Healthy         6112                1.0               1.0               1.0   \n",
      "\n",
      "          mean_r_mean  ...  brightness_std  contrast_mean  contrast_std  \\\n",
      "class                  ...                                                \n",
      "Diseased   165.173625  ...        6.189924      32.870601      8.196199   \n",
      "Dried      171.043830  ...        8.629475      45.446576      6.874067   \n",
      "Healthy    164.113787  ...        3.583067      26.991457      5.614187   \n",
      "\n",
      "          sat_clip_pct_mean  sharpness_laplacian_mean  \\\n",
      "class                                                   \n",
      "Diseased           0.002704                  8.572236   \n",
      "Dried              0.000048                 10.401794   \n",
      "Healthy            0.005188                  6.468205   \n",
      "\n",
      "          sharpness_laplacian_std  noise_proxy_mean  noise_proxy_std  \\\n",
      "class                                                                  \n",
      "Diseased                 3.491715          0.563379         0.121503   \n",
      "Dried                    2.846198          0.599189         0.113775   \n",
      "Healthy                  1.595994          0.496205         0.082438   \n",
      "\n",
      "          grayworld_std_mean  grayworld_std_max  \n",
      "class                                            \n",
      "Diseased            6.126856          10.841290  \n",
      "Dried               0.614679           5.786972  \n",
      "Healthy             5.428015          10.305400  \n",
      "\n",
      "[3 rows x 26 columns]\n",
      "\n",
      "Potential duplicate groups: 95\n",
      "Saved augmentation probe: /kaggle/working/eda_outputs/augmentation_probe.csv\n",
      "\n",
      "Final report saved to: /kaggle/working/eda_outputs/final_report.json\n",
      "Related work template saved to: /kaggle/working/eda_outputs/related_work_template.csv\n"
     ]
    }
   ],
   "source": [
    "# ======================================================================\n",
    "# CSE475 – TASK 1  (EDA + Related Work template helper)\n",
    "# Dataset: Betel Leaf (Healthy / Diseased / Dried)\n",
    "# Author: Shourav Deb\n",
    "# ======================================================================\n",
    "\n",
    "import os, json, math, glob\n",
    "from pathlib import Path\n",
    "\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "from PIL import Image, ImageFilter\n",
    "import cv2\n",
    "from tqdm import tqdm\n",
    "\n",
    "def get_row_class(row):\n",
    "    # Pandas renames 'class' -> '_1' in itertuples\n",
    "    return getattr(row, \"class\", getattr(row, \"_1\"))\n",
    "\n",
    "\n",
    "# ----------------------------------------------------------------------\n",
    "# 1. CONFIG\n",
    "# ----------------------------------------------------------------------\n",
    "\n",
    "DATA_ROOT = \"/kaggle/input/betel-leaf\"\n",
    "print(\"Using dataset root:\", DATA_ROOT)\n",
    "\n",
    "OUT_DIR = Path(\"/kaggle/working/eda_outputs\")\n",
    "OUT_DIR.mkdir(parents=True, exist_ok=True)\n",
    "\n",
    "# class names\n",
    "CLASS_NAMES = [\"Healthy\", \"Diseased\", \"Dried\"]\n",
    "\n",
    "# possible subfolders (On-Field + Controlled Environment)\n",
    "SPLIT_FOLDERS = [\n",
    "    \"Controlled Environment\",\n",
    "    \"Controlled_Environment\",\n",
    "    \"controlled_environment\",\n",
    "    \"On Field\",\n",
    "    \"On-Field\",\n",
    "    \"on_field\",\n",
    "    \"\",   # also check directly under root\n",
    "]\n",
    "\n",
    "# ----------------------------------------------------------------------\n",
    "# 2. INDEX ALL IMAGES\n",
    "# ----------------------------------------------------------------------\n",
    "records = []\n",
    "\n",
    "for split in SPLIT_FOLDERS:\n",
    "    split_path = Path(DATA_ROOT) / split if split != \"\" else Path(DATA_ROOT)\n",
    "    if not split_path.exists():\n",
    "        continue\n",
    "\n",
    "    for cls in CLASS_NAMES:\n",
    "        cls_path = split_path / cls\n",
    "        if not cls_path.exists():\n",
    "            continue\n",
    "        image_files = sorted(glob.glob(str(cls_path / \"*.jpg\"))) + \\\n",
    "                      sorted(glob.glob(str(cls_path / \"*.jpeg\"))) + \\\n",
    "                      sorted(glob.glob(str(cls_path / \"*.png\")))\n",
    "\n",
    "        for im in image_files:\n",
    "            records.append({\n",
    "                \"path\": im,\n",
    "                \"class\": cls,\n",
    "                \"split\": split if split != \"\" else \"root\"\n",
    "            })\n",
    "\n",
    "df_index = pd.DataFrame(records)\n",
    "index_csv_path = OUT_DIR / \"image_index.csv\"\n",
    "df_index.to_csv(index_csv_path, index=False)\n",
    "print(\"Total images found:\", len(df_index))\n",
    "print(df_index.head())\n",
    "\n",
    "if len(df_index) == 0:\n",
    "    raise RuntimeError(\"No images found. Check folder names / dataset mount.\")\n",
    "\n",
    "# ----------------------------------------------------------------------\n",
    "# 3. BASIC CLASS BALANCE\n",
    "# ----------------------------------------------------------------------\n",
    "class_counts = df_index.groupby([\"split\", \"class\"]).size().reset_index(name=\"count\")\n",
    "class_counts.to_csv(OUT_DIR / \"class_balance.csv\", index=False)\n",
    "print(\"\\nClass balance:\\n\", class_counts)\n",
    "\n",
    "# also a simpler global view\n",
    "global_counts = df_index[\"class\"].value_counts().reset_index()\n",
    "global_counts.columns = [\"class\", \"count\"]\n",
    "print(\"\\nGlobal class counts:\\n\", global_counts)\n",
    "global_counts.to_csv(OUT_DIR / \"class_balance_global.csv\", index=False)\n",
    "\n",
    "# ----------------------------------------------------------------------\n",
    "# 4. HELPER FUNCTIONS\n",
    "# ----------------------------------------------------------------------\n",
    "def load_rgb(path):\n",
    "    img = Image.open(path).convert(\"RGB\")\n",
    "    return np.array(img)\n",
    "\n",
    "def rgb_to_hsv_np(rgb):\n",
    "    # rgb: (H, W, 3) in 0..255\n",
    "    return cv2.cvtColor(rgb, cv2.COLOR_RGB2HSV)\n",
    "\n",
    "def image_brightness(img_rgb):\n",
    "    # simple brightness = mean of V in HSV\n",
    "    hsv = rgb_to_hsv_np(img_rgb)\n",
    "    return hsv[..., 2].mean()\n",
    "\n",
    "def image_contrast(img_rgb):\n",
    "    # std of grayscale / value channel\n",
    "    hsv = rgb_to_hsv_np(img_rgb)\n",
    "    return hsv[..., 2].std()\n",
    "\n",
    "def saturation_ratio(img_rgb, clip_thr=250):\n",
    "    hsv = rgb_to_hsv_np(img_rgb)\n",
    "    s = hsv[..., 1]\n",
    "    # % of pixels with very high saturation\n",
    "    return (s > clip_thr).mean()\n",
    "\n",
    "def laplacian_variance(img_rgb):\n",
    "    # blur/sharpness measure\n",
    "    gray = cv2.cvtColor(img_rgb, cv2.COLOR_RGB2GRAY)\n",
    "    return cv2.Laplacian(gray, cv2.CV_64F).var()\n",
    "\n",
    "def noise_proxy(img_rgb):\n",
    "    # difference between img and blurred version\n",
    "    img_f = img_rgb.astype(np.float32)\n",
    "    blur = cv2.GaussianBlur(img_f, (5,5), 0)\n",
    "    diff = np.abs(img_f - blur).mean()\n",
    "    return float(diff)\n",
    "\n",
    "# perceptual-ish average hash (no extra install)\n",
    "def average_hash(img_rgb, hash_size=8):\n",
    "    pil_img = Image.fromarray(img_rgb).convert(\"L\").resize((hash_size, hash_size), Image.LANCZOS)\n",
    "    pixels = np.array(pil_img)\n",
    "    avg = pixels.mean()\n",
    "    diff = pixels > avg\n",
    "    # convert to hex\n",
    "    bits = \"\".join(\"1\" if v else \"0\" for v in diff.flatten())\n",
    "    return hex(int(bits, 2))[2:].rjust(hash_size * hash_size // 4, \"0\")\n",
    "\n",
    "def aspect_ratio(w, h):\n",
    "    return round(w / h, 4)\n",
    "\n",
    "# ----------------------------------------------------------------------\n",
    "# 5. PER-IMAGE STATS LOOP\n",
    "# ----------------------------------------------------------------------\n",
    "per_image_records = []\n",
    "\n",
    "print(\"\\nComputing per-image statistics ...\")\n",
    "for row in tqdm(df_index.itertuples(index=False), total=len(df_index)):\n",
    "    img = load_rgb(row.path)\n",
    "    h, w, _ = img.shape\n",
    "\n",
    "    mean_rgb = img.mean(axis=(0,1))\n",
    "    std_rgb  = img.std(axis=(0,1))\n",
    "    hsv = rgb_to_hsv_np(img)\n",
    "    hist_h, _ = np.histogram(hsv[...,0], bins=16, range=(0,255))\n",
    "    hist_s, _ = np.histogram(hsv[...,1], bins=16, range=(0,255))\n",
    "    hist_v, _ = np.histogram(hsv[...,2], bins=16, range=(0,255))\n",
    "    br = image_brightness(img)\n",
    "    ct = image_contrast(img)\n",
    "    sat_clip = saturation_ratio(img, clip_thr=240)\n",
    "    sharp = laplacian_variance(img)\n",
    "    noise = noise_proxy(img)\n",
    "    gw_diff = float(np.std(mean_rgb))\n",
    "    ahash = average_hash(img, hash_size=8)\n",
    "\n",
    "    per_image_records.append({\n",
    "        \"path\": row.path,\n",
    "        \"class\": get_row_class(row),\n",
    "        \"split\": row.split,\n",
    "        \"width\": w,\n",
    "        \"height\": h,\n",
    "        \"aspect_ratio\": aspect_ratio(w, h),\n",
    "        \"mean_r\": float(mean_rgb[0]),\n",
    "        \"mean_g\": float(mean_rgb[1]),\n",
    "        \"mean_b\": float(mean_rgb[2]),\n",
    "        \"std_r\": float(std_rgb[0]),\n",
    "        \"std_g\": float(std_rgb[1]),\n",
    "        \"std_b\": float(std_rgb[2]),\n",
    "        \"brightness\": float(br),\n",
    "        \"contrast\": float(ct),\n",
    "        \"sat_clip_pct\": float(sat_clip),\n",
    "        \"sharpness_laplacian\": float(sharp),\n",
    "        \"noise_proxy\": float(noise),\n",
    "        \"grayworld_std\": float(gw_diff),\n",
    "        \"hash\": ahash,\n",
    "        \"hist_h\": hist_h.tolist(),\n",
    "        \"hist_s\": hist_s.tolist(),\n",
    "        \"hist_v\": hist_v.tolist(),\n",
    "    })\n",
    "\n",
    "df_stats = pd.DataFrame(per_image_records)\n",
    "df_stats.to_pickle(OUT_DIR / \"per_image_stats.pkl\")  # convenient\n",
    "df_stats.to_csv(OUT_DIR / \"per_image_stats.csv\", index=False)\n",
    "print(\"Saved per-image stats to:\", OUT_DIR / \"per_image_stats.csv\")\n",
    "\n",
    "# ----------------------------------------------------------------------\n",
    "# 6. PER-CLASS AGGREGATION\n",
    "# ----------------------------------------------------------------------\n",
    "agg_funcs = {\n",
    "    \"width\": [\"mean\", \"min\", \"max\"],\n",
    "    \"height\": [\"mean\", \"min\", \"max\"],\n",
    "    \"aspect_ratio\": [\"mean\", \"min\", \"max\"],\n",
    "    \"mean_r\": \"mean\",\n",
    "    \"mean_g\": \"mean\",\n",
    "    \"mean_b\": \"mean\",\n",
    "    \"std_r\": \"mean\",\n",
    "    \"std_g\": \"mean\",\n",
    "    \"std_b\": \"mean\",\n",
    "    \"brightness\": [\"mean\", \"std\"],\n",
    "    \"contrast\": [\"mean\", \"std\"],\n",
    "    \"sat_clip_pct\": [\"mean\"],\n",
    "    \"sharpness_laplacian\": [\"mean\", \"std\"],\n",
    "    \"noise_proxy\": [\"mean\", \"std\"],\n",
    "    \"grayworld_std\": [\"mean\", \"max\"],\n",
    "}\n",
    "\n",
    "df_class = df_stats.groupby(\"class\").agg(agg_funcs)\n",
    "df_class.columns = [\"_\".join(c for c in col if c) for col in df_class.columns.ravel()]\n",
    "df_class.to_csv(OUT_DIR / \"per_class_summary.csv\")\n",
    "print(\"\\nPer-class summary:\\n\", df_class)\n",
    "\n",
    "# ----------------------------------------------------------------------\n",
    "# 7. RESOLUTION & ASPECT-RATIO DISTRIBUTION\n",
    "# ----------------------------------------------------------------------\n",
    "res_counts = df_stats.groupby([\"width\", \"height\"]).size().reset_index(name=\"count\")\n",
    "res_counts.to_csv(OUT_DIR / \"resolution_distribution.csv\", index=False)\n",
    "\n",
    "ar_counts = df_stats[\"aspect_ratio\"].value_counts().reset_index()\n",
    "ar_counts.columns = [\"aspect_ratio\", \"count\"]\n",
    "ar_counts.to_csv(OUT_DIR / \"aspect_ratio_distribution.csv\", index=False)\n",
    "\n",
    "# ----------------------------------------------------------------------\n",
    "# 8. DUPLICATE / NEAR-DUPLICATE DETECTION\n",
    "#    (same hash -> very likely same image; we just dump groups)\n",
    "# ----------------------------------------------------------------------\n",
    "dup_groups = df_stats.groupby(\"hash\")[\"path\"].apply(list).reset_index()\n",
    "dup_groups = dup_groups[dup_groups[\"path\"].apply(len) > 1]\n",
    "dup_groups.to_json(OUT_DIR / \"duplicate_candidates.json\", orient=\"records\", indent=4)\n",
    "print(\"\\nPotential duplicate groups:\", len(dup_groups))\n",
    "\n",
    "# ----------------------------------------------------------------------\n",
    "# 9. AUGMENTATION PROBE\n",
    "#    we just check if simple augs break aspect ratio / size / class distribution\n",
    "# ----------------------------------------------------------------------\n",
    "import random\n",
    "from PIL import ImageEnhance\n",
    "\n",
    "def random_augment(pil_img):\n",
    "    choice = random.choice([\"flip\", \"crop\", \"color\", \"blur\"])\n",
    "    if choice == \"flip\":\n",
    "        return pil_img.transpose(Image.FLIP_LEFT_RIGHT), \"hflip\"\n",
    "    elif choice == \"crop\":\n",
    "        w, h = pil_img.size\n",
    "        cw, ch = int(w*0.9), int(h*0.9)\n",
    "        left = (w - cw)//2\n",
    "        top = (h - ch)//2\n",
    "        return pil_img.crop((left, top, left+cw, top+ch)).resize((w, h)), \"center_crop\"\n",
    "    elif choice == \"color\":\n",
    "        enh = ImageEnhance.Color(pil_img)\n",
    "        return enh.enhance(1.5), \"color_jitter\"\n",
    "    else:\n",
    "        return pil_img.filter(ImageFilter.GaussianBlur(radius=1.0)), \"blur\"\n",
    "\n",
    "probe_results = []\n",
    "probe_samples = df_index.sample(min(30, len(df_index)), random_state=42)\n",
    "\n",
    "for row in probe_samples.itertuples(index=False):\n",
    "    img = Image.open(row.path).convert(\"RGB\")\n",
    "    aug_img, aug_name = random_augment(img)\n",
    "    arr = np.array(aug_img)\n",
    "    probe_results.append({\n",
    "        \"path\": row.path,\n",
    "        \"class\": get_row_class(row),\n",
    "        \"aug\": aug_name,\n",
    "        \"after_w\": arr.shape[1],\n",
    "        \"after_h\": arr.shape[0],\n",
    "        \"after_brightness\": float(image_brightness(arr)),\n",
    "        \"after_contrast\": float(image_contrast(arr)),\n",
    "    })\n",
    "\n",
    "df_probe = pd.DataFrame(probe_results)\n",
    "df_probe.to_csv(OUT_DIR / \"augmentation_probe.csv\", index=False)\n",
    "print(\"Saved augmentation probe:\", OUT_DIR / \"augmentation_probe.csv\")\n",
    "\n",
    "# ----------------------------------------------------------------------\n",
    "# 10. FINAL JSON REPORT  (for Task 1 submission)\n",
    "# ----------------------------------------------------------------------\n",
    "final_report = {\n",
    "    \"total_images\": int(len(df_index)),\n",
    "    \"by_class\": global_counts.to_dict(orient=\"records\"),\n",
    "    \"by_split_class\": class_counts.to_dict(orient=\"records\"),\n",
    "    \"resolution_modes\": res_counts.sort_values(\"count\", ascending=False).head(10).to_dict(orient=\"records\"),\n",
    "    \"aspect_ratio_top\": ar_counts.sort_values(\"count\", ascending=False).head(10).to_dict(orient=\"records\"),\n",
    "    \"per_class_summary_csv\": str(OUT_DIR / \"per_class_summary.csv\"),\n",
    "    \"duplicates_found\": int(len(dup_groups)),\n",
    "    \"dup_file\": str(OUT_DIR / \"duplicate_candidates.json\"),\n",
    "    \"augmentation_probe_csv\": str(OUT_DIR / \"augmentation_probe.csv\"),\n",
    "    \"notes\": \"Generated for CSE475 Task 1 – image-focused EDA.\",\n",
    "}\n",
    "\n",
    "with open(OUT_DIR / \"final_report.json\", \"w\") as f:\n",
    "    json.dump(final_report, f, indent=4)\n",
    "\n",
    "print(\"\\nFinal report saved to:\", OUT_DIR / \"final_report.json\")\n",
    "\n",
    "# ----------------------------------------------------------------------\n",
    "# 11. RELATED WORK TABLE TEMPLATE (Task 1)\n",
    "# ----------------------------------------------------------------------\n",
    "related_work_cols = [\n",
    "    \"Title\",\n",
    "    \"Dataset name and URL\",\n",
    "    \"Dataset description\",\n",
    "    \"Methods name\",\n",
    "    \"Accuracy of the model\",\n",
    "    \"Pros\",\n",
    "    \"Cons\",\n",
    "    \"Citation\",\n",
    "]\n",
    "df_rw = pd.DataFrame(columns=related_work_cols)\n",
    "df_rw.to_csv(OUT_DIR / \"related_work_template.csv\", index=False)\n",
    "print(\"Related work template saved to:\", OUT_DIR / \"related_work_template.csv\")\n"
   ]
  }
 ],
 "metadata": {
  "kaggle": {
   "accelerator": "none",
   "dataSources": [
    {
     "datasetId": 8592258,
     "sourceId": 13531560,
     "sourceType": "datasetVersion"
    }
   ],
   "dockerImageVersionId": 31153,
   "isGpuEnabled": false,
   "isInternetEnabled": true,
   "language": "python",
   "sourceType": "notebook"
  },
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
